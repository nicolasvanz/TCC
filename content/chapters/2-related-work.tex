\glsresetall
\chapter{Trabalhos Relacionados}
\label{chap.related-work}

Neste capítulo, serão mostradas técnicas e pesquisas que estão sendo desenvolvidas no que diz respeito à virtualização e migração. Serão apresentados trabalhos relacionados, bem como serão evidenciadas as semelhanças e diferenças com o presente trabalho.

Grande parte das pesquisas relacionadas à migração estão inseridas em ambientes \cloud. Nesses casos, os esforços estão voltados para redução do tempo total de migração, diminuição do \downtime~\cite{migration-linux-conteiners,clark2005live} e exploração/otimização das vantagens que a migração de processos oferece nesses ambientes computacionais. Entre essas vantagens podem-se citar:
\begin{enumerate}[label=(\roman*)]
    \item Balanceamento de carga~\cite{live-vm-migration-techniques,ada-things};
    \item Tolerância a falhas~\cite{fernando2019live};
    \item Gerenciamento do consumo de energia~\cite{aldossary2018performance};
    \item Compartilhamento de recursos; e
    \item Manutenção de sistemas sem interrupções~\cite{live-vm-migration-techniques,ada-things}.
\end{enumerate}

Apesar da maioria das pesquisas estarem voltadas à exploração desses benefícios e diminuição do tempo de migração e \downtime em ambientes \cloud, há alguns autores preocupados com o desenvolvimento de soluções envolvendo virtualização e migração em ambientes de recursos restritos, como sistemas de tempo real e sistemas críticos, nos quais há restrições de tempo também. Dessa forma, como a temática de limitação de recursos, especialmente de memória, é muito presente neste trabalho, serão abordados nas próximas seções algumas pesquisas desses autores, \ie pesquisas voltadas à busca pelo uso da virtualização/migração de forma mais leve e cujo impacto no \hardware seja reduzido, adaptando-se a esses sistemas de recursos limitados.

\section{\textit{''Virtualization on TrustZone-enabled Microcontrollers?\\ Voilà!''}}\label{sec.rw-1}

O artigo \textit{''Virtualization on TrustZone-enabled Microcontrollers? Voilà!''}~\cite{pinto2019virtualization} aborda a possibilidade de implementação da virtualização em microcontroladores que utilizam \trustzone. \trustzone é uma tecnologia de \hardware voltada à segurança, em que a execução de um sistema pode ser dividida entre normal e segura. Os autores afirmam que essa tecnologia pode ser explorada além das suas propriedades de segurança. Isso porque o \trustzone também provê certo nível de isolamento dos recursos, o que o torna viável de ser usado para virtualização, afinal o isolamento cria um ambiente seguro e propício para a execução simultânea e isolada de múltiplas \vms.

\citeonline{pinto2019virtualization} expõe a dificuldade de se implementar a virtualização em \mcus devido aos seus recursos limitados. Nesses ambientes, não é possível a utilização de \hypervisors tradicionais, haja vista a baixa complexidade de \hardware das \mcus. Sendo assim, para atender a necessidade de baixo impacto nos recursos dos \mcus, os autores propõem uma solução que usa um \hypervisor mais leve para gerenciar as \vms nesses ambientes utilizando a tecnologia \trustzone para garantir o isolamento das \vms.

Os testes foram feitos num microcontrolador \textit{Cortex-M4} e a solução proposta garante o suporte à execução múltipla de \vms em microcontroladores.

\section{\textit{''Checkpointing and migration of IoT edge functions''}}\label{sec.rw-2}


O artigo \textit{''Checkpointing and migration of IoT edge functions''}~\cite{karhula2019checkpointing} propõe um artifício envolvendo migração de contêineres entre dispositivos \iot de borda como solução para a diminuição do uso de recursos em dispositivos \iot.

Os autores evidenciam que os aparelhos \iot são usados na computação de borda para promover o que chamamos de \faas, que é um tipo de serviço oferecido por diversas plataformas, como a \textit{Amazon AWS Lambda} e \textit{Google Cloud Functions}. Contudo, dispositivos \iot possuem recursos limitados, restringindo-se à execução de poucos contêineres simultaneamente. Além disso, as abordagens tradicionais de \faas sugerem a execução ininterrupta dos contêineres que são iniciados. Isso torna a computação de borda ineficiente, pois esse esquema pode sobrecarregar rapidamente os dispositivos \iot, haja vista a memória limitada desses. A situação se agrava ainda mais quando consideramos funções de longa duração bloqueantes (muito comuns em sistemas de autenticação) \eg funções que esperam alguma requisição, resposta ou qualquer tipo de sinal de outro sistema, seja ele um outro dispositivo \iot ou uma ação humana.

Dessa forma, \citeonline{karhula2019checkpointing} propõem um esquema de \checkpointing utilizando \docker e \criu. Através dessas tecnologias, os contêineres que não estão executando computação útil são interrompidos e salvos em disco, liberando espaço da memória para a execução de outro contêiner. Isso se torna extremamente útil quando consideramos funções de longa duração bloqueantes, já que durante o tempo de espera pelo sinal, a aplicação pode ser interrompida. Além disso, com o estado salvo em disco, a migração de contêineres entre dispositivos \iot de borda se torna possível. Dessa forma, além de reduzir o uso de recursos nos dispositivos de computação em borda, através da migração dos contêineres, outros benefícios surgem, como o balanceamento de carga e tolerância a falhas entre aparelhos \iot de borda.

Os testes foram feitos em uma \textit{Raspberry Pi 2 Model B}, a qual rodava diversos contêineres com aplicações em \textit{Node JS} de longa duração e que simulavam o comportamento bloqueante. Os resultados apontam que houve economia no uso de recursos, em especial da memória, e que a migração de contêineres entre dispositivos \iot de borda é possível.

\section{ \textit{''Lightweight virtualization as enabling technology for future smart cars''}}\label{sec.rw-3}

O artigo \textit{''Lightweight virtualization as enabling technology for future smart cars''} \cite{smartcarslwvirtualization} discorre sobre a possibilidade de usar a virtualização no desenvolvimento de aplicações para carros inteligentes. Os sistemas presentes nos carros inteligentes também têm certa limitação de recursos que dificultam a aplicação direta de \hypervisors tradicionais, muito comuns em ambientes \cloud.

Sendo assim, os autores propõem um sistema que utiliza contêineres \docker para criar uma camada de abstração a nível de processo. Dessa forma, cada aplicação é executada em um contêiner distinto. Esse sistema tem impacto menor nos recursos de \hardware e é suficiente para garantir a execução isolada das aplicações virtuais (contêineres).

Além disso, o sistema engloba um escalonador de contêineres, que é responsável por gerenciar os contêineres e o \hardware alocado para cada um. Ademais, tem finalidade de sinalizar a instanciação e destruição dos contêineres conforme a necessidade. Esse escalonador é capaz de gerenciar os recursos de \hardware de forma a garantir que os contêineres sejam executados de maneira eficiente, sem que haja desperdício de recursos. No modelo proposto pelos autores, há 4 tipos de tarefas: \critical, \high, \moderate e \low. Cada um desses tipos possui um nível de prioridade, sendo que o \critical é o mais prioritário e o \low é o menos prioritário. O escalonador é responsável por garantir que as tarefas de maior prioridade sejam executadas primeiro. Tarefas relacionadas à segurança dos passageiros \eg sistemas de alerta ou câmera são consideradas mais prioritárias que tarefas relacionadas à sistemas de entretenimento \eg sistemas de áudio ou vídeo.

A proposta foi testada em uma \textit{Raspberry Pi 3} e os resultados foram considerados positivos. Os contêineres garantiram a execução do sistema de maneira a considerar a limitação de \hardware e suportaram a execução paralela de múltiplas aplicações. O escalonador de contêineres foi capaz de gerenciar os recursos de maneira eficiente, priorizando as tarefas de maior prioridade.

\section{\textit{''Container-based real-time scheduling in the linux kernel''}}\label{sec.rw-4}

O artigo \textit{''Container-based real-time scheduling in the linux kernel''} \cite{abeni2019container} aborda o tema de virtualização com contêineres em sistemas de tempo real. Os autores exploram a implementação de um escalonador de tarefas em sistemas de tempo real utilizando \lxc (\ie com o auxílio de \cgroups e \namespaces). 

\citeonline{abeni2019container} explicam que os componentes que constituem os ambientes de sistemas de tempo real tradicionalmente eram executados por uma \vm dedicada, em que as \vms eram gerenciadas por um \hypervisor escalonador. Os autores afirmam que em algumas situações (\eg em sistemas embarcados) pode ser vantajosa a utilização de uma virtualização mais leve, baseada em contêineres, já que este tipo de virtualização sobrecarrega menos o sistema quando comparada com a abordagem de virtualização total tradicionalmente utilizada.

Desse modo os autores propõem um escalonador que estende um escalonador já presente no \kernel do \linux, o SCHED\_DEADLINE. A implementação consiste em um sistema de escalonamento em uma hierarquia de dois níveis. No primeiro nível, o qual é responsável pelo escalonamento dos \cgroups, é utilizada a política de escalonamento do SCHED\_DEADLINE e no segundo nível é utilizada uma política de escalonamento com prioridade fixa, como o SCHED\_FIFO ou SCHED\_RR.
Resumidamente, no momento em que a política de escalonamento SCHED\_DEADLINE escalona uma entidade que está associada a uma fila de \tasks de tempo real, então o escalonador de prioridade fixa seleciona a \task de maior prioridade.

Os experimentos mostraram que o escalonador proposto fez com que os \cores fossem utilizados de um forma melhor, quando compara-se com escalonadores que utilizam a virtualização total. Isso porque, em contraste com a virtualização total, na virtualização com contêineres, os componentes compartilham o mesmo \kernel. Sendo assim, é possível a migração de \tasks para filas de \cores menos utilizados.

\section{Comparação do Presente Trabalho com os Trabalhos Relacionados}

O presente trabalho se assemelha com os trabalhos relacionados apresentados no sentido de aplicar a virtualização e migração em um sistema com recursos restritos. De maneira similar aos trabalhos detalhados nas Seções \ref{sec.rw-2}, \ref{sec.rw-3} e \ref{sec.rw-4} e em contraste com o trabalho detalhado na Seção \ref{sec.rw-1}, neste trabalho foi explorado um modelo de virtualização baseado na utilização de contêineres. Isso foi feito com o intuito de evitar a sobrecarga que a virtualização total tem sobre o ambiente, em especial na memória, que nos \lws é escassa.

Neste trabalho, não foi utilizada qualquer ferramenta de auxílio na manipulação de contêineres, em contraste com os trabalhos apresentados, que usufruem de mecanismos de gerenciamento de contêineres, como o Docker~\cite{smartcarslwvirtualization,karhula2019checkpointing} ou o \lxc~\cite{abeni2019container}. Isso porque o trabalho é feito sobre um ambiente não usual, os \lws, utilizando um \so ainda incomum para a prática dessas técnicas, o \nanvix. Dessa forma, a criação de um contêiner e a forma como este é manipulado foram desenvolvidas desde o início e especificamente para o \nanvix. Isso traz à implementação algumas características peculiares. Por exemplo, os contêineres executam sobre uma estrutura de \kernel idêntica, se diferenciando pelo contexto do processo, o que é uma característica comumente vista na virtualização a nível de \so. Contudo, o \kernel não é compartilhado entre os contêineres, já que em um \cluster temos exatamente um contêiner e os \clusters são independentes entre si. Logo, um contêiner tem acesso completo aos recursos do \cluster em que executa e o \cluster tem visão apenas do contêiner que hospeda. Então, o gerenciamento desses contêineres precisa ser feito em um nível de abstração maior, em que se tem uma visão do processador como um todo, e não somente de um \cluster.

Além disso, em contraste com os trabalhos apresentados, a principal vantagem explorada com a virtualização é o aumento da mobilidade dos processos, possibilitando a migração de processos. A utilização eficiente dos recursos promovida pela virtualização, mesmo que necessária nos \lws pela limitação de recursos computacionais (em especial a memória) se torna uma vantagem indireta da virtualização. Isso porque o uso eficiente de \hardware é provido mais pela migração (através da melhor disposição dos processos entre os \clusters) do que pela virtualização em si.

